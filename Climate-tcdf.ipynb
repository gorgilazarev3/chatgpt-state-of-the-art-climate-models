{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "model_sentiment = pipeline(\"sentiment-analysis\", model=\"climatebert/distilroberta-base-climate-tcfd\",device=0)\n",
    "#model_sentiment = pipeline(\"sentiment-analysis\",device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_parquet(\"test-tcdf.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv file into a df2\n",
    "df2 = pd.read_csv(\"test-tcdf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 0, 4, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df unique values label\n",
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictiony that maps the following governance, strategy, risk management, metrics and targets in numbers\n",
    "# 0: governance, 1: strategy, 2: risk management, 3: metrics and targets\n",
    "mappint_dict = {'governance': 4, 'strategy': 2, 'risk': 3, 'metrics':1, 'none':0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text\n",
       "label      \n",
       "0        80\n",
       "1        49\n",
       "2       197\n",
       "3        48\n",
       "4        26"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['label'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctext = \"text\"\n",
    "sent_col = \"prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'strategy', 'score': 0.36417022347450256}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sentiment(\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimit\\AppData\\Local\\Temp\\ipykernel_24720\\1921190832.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[sent_col] = \"none\"\n",
      "C:\\Users\\dimit\\AppData\\Local\\Temp\\ipykernel_24720\\1921190832.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[sent_col+\"_VALUE\"] = 0\n",
      "c:\\ProgramData\\Anaconda3\\envs\\trans\\lib\\site-packages\\transformers\\pipelines\\base.py:1045: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 200 300 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimit\\AppData\\Local\\Temp\\ipykernel_24720\\1921190832.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[sent_col] = sent\n",
      "C:\\Users\\dimit\\AppData\\Local\\Temp\\ipykernel_24720\\1921190832.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[sent_col+\"_VALUE\"] = s_val\n"
     ]
    }
   ],
   "source": [
    "df[sent_col] = \"none\"\n",
    "df[sent_col+\"_VALUE\"] = 0\n",
    "i = 0\n",
    "sent = []\n",
    "s_val = []\n",
    "for s in df[ctext].to_list():\n",
    "    #print(s)\n",
    "    i+=1\n",
    "    if i%100 ==0:\n",
    "        print(i,end=\" \")\n",
    "    if len(s)>1:\n",
    "        if(len(s)>2000):\n",
    "            s=s[:2000]\n",
    "        result = model_sentiment(s)[0]\n",
    "        # map the result['label'] into numbers using the mapping_dict dictionary, if the value is not in the dictionary, then it is mapped to 0\n",
    "        rez = mappint_dict.get(result['label'].lower(),0)\n",
    "        sent.append(rez)\n",
    "        s_val.append(-result['score'])\n",
    "    else:\n",
    "        sent.append(0)\n",
    "        s_val.append(0)\n",
    "df[sent_col] = sent\n",
    "df[sent_col+\"_VALUE\"] = s_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7049889543446244, 0.7176506755572202, 0.7096307121882569, None)\n",
      "[[ 36  10   3   0]\n",
      " [ 17 166  10   4]\n",
      " [  2  14  27   5]\n",
      " [  1   4   2  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.73      0.69        49\n",
      "           2       0.86      0.84      0.85       197\n",
      "           3       0.64      0.56      0.60        48\n",
      "           4       0.68      0.73      0.70        26\n",
      "\n",
      "    accuracy                           0.78       320\n",
      "   macro avg       0.70      0.72      0.71       320\n",
      "weighted avg       0.78      0.78      0.77       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the precision and f1 score for df columns label and prediction\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "print(precision_recall_fscore_support(df['label'], df[sent_col], average='macro'))\n",
    "\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(df['label'], df[sent_col]))\n",
    "\n",
    "# performnce report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(df['label'], df[sent_col]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prediction_VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sustainable strategy ‘red lines’ For our susta...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.900904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Verizon’s environmental, health and safety man...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.890918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In 2019, the Company closed a series of transa...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.923925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In December 2020, the AUC approved the Electri...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.764115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finally, there is a reputational risk linked t...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.956473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Indirect emissions result from operational act...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.955989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>All data in this TCFD report is as of, or for ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.870182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>Outcome: The bank explained that it would be w...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.882809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>In 2020, Banco do Brasil Foundation celebrated...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.874456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Climate change is producing changes in weather...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.977737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  prediction   \n",
       "0    Sustainable strategy ‘red lines’ For our susta...      2           2  \\\n",
       "1    Verizon’s environmental, health and safety man...      3           3   \n",
       "2    In 2019, the Company closed a series of transa...      2           2   \n",
       "3    In December 2020, the AUC approved the Electri...      2           2   \n",
       "4    Finally, there is a reputational risk linked t...      2           2   \n",
       "..                                                 ...    ...         ...   \n",
       "392  Indirect emissions result from operational act...      1           1   \n",
       "393  All data in this TCFD report is as of, or for ...      2           1   \n",
       "394  Outcome: The bank explained that it would be w...      1           2   \n",
       "395  In 2020, Banco do Brasil Foundation celebrated...      2           2   \n",
       "396  Climate change is producing changes in weather...      2           2   \n",
       "\n",
       "     prediction_VALUE  \n",
       "0           -0.900904  \n",
       "1           -0.890918  \n",
       "2           -0.923925  \n",
       "3           -0.764115  \n",
       "4           -0.956473  \n",
       "..                ...  \n",
       "392         -0.955989  \n",
       "393         -0.870182  \n",
       "394         -0.882809  \n",
       "395         -0.874456  \n",
       "396         -0.977737  \n",
       "\n",
       "[320 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"gpt2\")\n",
    "with open('c:\\\\data\\\\openAI-key-g.txt', 'r') as file:\n",
    "    key = file.readline()\n",
    "openai.api_key = key\n",
    "\n",
    "# sava the key in the environment variable\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "def get_first_number(s):\n",
    "    for i in range(len(s)):\n",
    "        if s[i].isdigit():\n",
    "            return int(s[i])\n",
    "    # There is no number in the string, so search for the mapping_dict keys\n",
    "    # find the if the some key from mappint_dict is in s and return the value, make the comarioson case insensitive\n",
    "    for k in mappint_dict.keys():\n",
    "        if k in s.lower():\n",
    "            return mappint_dict[k]\n",
    "    return -1\n",
    "\n",
    "def batch_gpt_len(prompt,target_texts, batch_size):\n",
    "    l = len(target_texts)\n",
    "    rez_keys = []\n",
    "    rez_vals = []\n",
    "    rez = []\n",
    "    i =0\n",
    "    while i < l:\n",
    "        text = \"\"\n",
    "        for j in range(batch_size):\n",
    "            if i<l:\n",
    "                if batch_size > 1:\n",
    "                    text += f\"{i}. \"+target_texts[i]+\"\\n\\n\"\n",
    "                else:\n",
    "                    text += target_texts[i]\n",
    "            i += 1\n",
    "        p = prompt + text\n",
    "        #print(f\"Prompt ({len(p)}):\", p)\n",
    "        # print(i, len(p))\n",
    "\n",
    "        # try the API call and if it fails, wait 10 seconds and retry again (max 3 times)\n",
    "        for j in range(6):\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[{\"role\": \"user\", \"content\": p}]\n",
    "                )\n",
    "                break\n",
    "            except:\n",
    "                print(\"error calling API, retrying...\")\n",
    "                time.sleep(10)\n",
    "        \n",
    "        r = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        rez.append(r)\n",
    "        # convert r to int\n",
    "        try:\n",
    "            b = get_first_number(r)\n",
    "        except:\n",
    "            b = -1\n",
    "            print(\"error parsing\"+r)\n",
    "        print(i, len(p), \"-\", r, b, end=\": \")\n",
    "        # if i % 10 print \n",
    "        if i % 10 == 0:\n",
    "            print()\n",
    "        rez_keys.append(b)\n",
    "    return rez,rez_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"text\"].to_list()\n",
    "prompt = '''\n",
    "Classify the following climate related text in one of the four classes: {}'metrics':1, 'strategy': 2, 'risk': 3,'governance': 4}.\n",
    "Answer only with the class number and nothing else. The text is: \\n\n",
    "'''\n",
    "rez, rez_keys = batch_gpt_len(prompt, texts, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 417 - 2 2: 2 875 - 3 3: 3 804 - 3 3: 4 1117 - 4 4: 5 607 - 3 3: 6 576 - 3 3: 7 573 - 3 3: 8 717 - 4 4: 9 492 - 3 3: 10 448 - 3 3: \n",
      "11 460 - 1 1: 12 414 - 3 3: 13 473 - 2 2: 14 634 - 3 3: 15 557 - 3 3: 16 388 - 3 3: 17 864 - 3 3: 18 623 - 4 4: 19 899 - governance (4) class. 4: 20 844 - Metrics 1: \n",
      "21 799 - 3 3: 22 550 - 3 3: 23 499 - 2 2: 24 439 - 1 1: 25 670 - 3 3: 26 802 - 3 3: 27 800 - 1 1: 28 397 - 3 3: 29 496 - 2 2: 30 691 - 3 3: \n",
      "31 855 - 2 2: 32 1025 - 4 4: 33 780 - 2 2: 34 522 - 4 4: 35 695 - 3 3: 36 512 - 2 2: 37 612 - 3 3: 38 490 - 3 3: 39 767 - 1 1: 40 646 - 2 2: \n",
      "41 438 - 2 2: 42 485 - 4 4: 43 745 - 3 3: 44 742 - 4 4: 45 456 - 1 1: 46 417 - 3 3: 47 406 - 1 1: 48 643 - 3 3: 49 512 - 3 3: 50 1335 - governance 4: \n",
      "51 646 - 2 2: 52 610 - 3 3: 53 422 - 4 4: 54 541 - 2 2: 55 567 - 1 1: 56 479 - 2 2: 57 807 - 2 2: 58 1580 - 3 (risk) 3: 59 405 - 4 4: 60 1166 - governance 4: \n",
      "61 443 - 4 4: 62 620 - 2 2: 63 724 - 3 3: 64 867 - 3 3: 65 1040 - 3 (risk) 3: 66 795 - 1 1: 67 752 - 3 3: 68 1244 - strategy 2: 69 569 - 2 2: 70 620 - 3 3: \n",
      "71 560 - 3 3: 72 430 - 4 4: 73 499 - 2 2: 74 709 - 4 4: 75 502 - 4 4: 76 531 - 4 4: 77 947 - 3 3: 78 727 - strategy (2) 2: 79 559 - 3 3: 80 622 - 4 4: \n",
      "81 609 - 3 3: 82 538 - 3 3: 83 540 - 3 3: 84 1279 - Metrics 1: 85 636 - 2 2: 86 487 - 2 2: 87 927 - metrics 1: 88 531 - 4 4: 89 713 - 2 2: 90 805 - 4 4: \n",
      "91 437 - 1 1: 92 861 - 2 2: 93 847 - 3 3: 94 794 - 4 4: 95 654 - 2 2: 96 404 - 3 3: 97 621 - 4 4: 98 4063 - 3 3: 99 472 - 1 1: 100 685 - governance (4) 4: \n",
      "101 527 - 3 3: 102 1065 - 3 3: 103 480 - 4 4: 104 623 - 1 1: 105 693 - 4 4: 106 467 - 4 4: 107 630 - 3 3: 108 1011 - 3 3: 109 601 - 4 4: 110 760 - 3 3: \n",
      "111 348 - 4 4: 112 509 - 2 2: 113 534 - 4 4: 114 769 - 4 4: 115 651 - 2 2: 116 939 - metrics 1: 117 604 - 3 3: 118 1334 - 4 (governance) 4: 119 651 - 2 2: 120 589 - 4 4: \n",
      "121 787 - 3 3: 122 414 - 4 4: 123 514 - 3 3: 124 487 - 3 3: 125 530 - 3 3: 126 591 - 3 3: 127 846 - 4 4: 128 616 - 4 4: 129 585 - 3 3: 130 604 - 3 3: \n",
      "131 583 - 3 3: 132 511 - 2 2: 133 598 - 1 1: 134 758 - 4 4: 135 751 - 4 4: 136 826 - 2 2: 137 406 - 2 2: 138 584 - 4 4: 139 444 - 4 4: 140 536 - 3 3: \n",
      "141 797 - 4 4: 142 534 - 2 2: 143 2851 - metrics 1: 144 665 - 3 3: 145 775 - 3 3: 146 920 - Governance (4) 4: 147 1189 - Governance (4) 4: 148 1807 - metrics 1: 149 957 - strategy 2: 150 618 - 2 2: \n",
      "151 451 - 3 3: 152 999 - 4 4: 153 1045 - 3 3: 154 875 - 3 3: 155 926 - 4 (governance) 4: 156 756 - 4 4: 157 791 - 3 3: 158 657 - 2 2: 159 674 - 2 2: 160 672 - 2 2: \n",
      "161 780 - 4 4: 162 634 - 3 3: 163 682 - 3 3: 164 566 - 4 4: 165 517 - 2 2: 166 598 - 3 3: 167 749 - 4 4: 168 744 - 4 4: 169 723 - 3 3: 170 774 - 4 4: \n",
      "171 499 - 1 1: 172 630 - 2 2: 173 784 - 3 3: 174 1661 - 3 (risk) 3: 175 904 - 3 3: 176 562 - 3 3: 177 1043 - 3 3: 178 440 - 1 1: 179 569 - 1 1: 180 425 - 4 4: \n",
      "181 685 - 3 3: 182 760 - 4 4: 183 822 - governance 4: 184 3053 - 3 3: 185 535 - 2 2: 186 923 - Governance (4) 4: 187 553 - 3 3: 188 698 - 1 1: 189 363 - 3 3: 190 868 - Governance (4) 4: \n",
      "191 384 - 1 1: 192 469 - 2 2: 193 858 - 2 2: 194 713 - 4 4: 195 718 - 4 4: 196 1059 - 4 4: 197 465 - 2 2: 198 818 - 3 3: 199 733 - 4 4: 200 523 - 1 1: \n",
      "201 780 - 4 4: 202 571 - 3 3: 203 591 - 4 4: 204 566 - 2 2: 205 759 - 3 3: 206 662 - 4 4: 207 516 - 4 4: 208 964 - 3 3: 209 418 - 1 1: 210 1486 - Governance (4) 4: \n",
      "211 463 - 4 4: 212 1122 - 3 3: 213 1060 - metrics 1: 214 598 - 3 3: 215 838 - 4 4: 216 629 - 3 3: 217 1072 - 3 3: 218 480 - 4 4: 219 784 - 4 4: 220 583 - 2 2: \n",
      "221 556 - 2 2: 222 491 - 3 3: 223 525 - 3 3: 224 620 - 1 1: 225 411 - 3 3: 226 561 - 3 3: 227 604 - 3 3: 228 898 - metrics 1: 229 613 - 2 2: 230 1090 - metrics 1: \n",
      "231 673 - 4 4: 232 724 - 2 2: 233 776 - 4 4: 234 565 - 3 3: 235 984 - 3 (risk) 3: 236 797 - 4 4: 237 523 - 1 1: 238 1865 - governance 4: 239 626 - 3 3: 240 501 - 4 4: \n",
      "241 624 - 3 3: 242 789 - 3 3: 243 541 - 1 1: 244 862 - 2 2: 245 452 - 2 2: 246 434 - 3 3: 247 492 - 4 4: 248 642 - metrics 1: 249 1182 - 4 4: 250 553 - 3 3: \n",
      "251 912 - 3 (risk) 3: 252 806 - metrics 1: 253 647 - 4 4: 254 753 - 4 4: 255 418 - 4 4: 256 603 - 4 4: 257 612 - 3 3: 258 1042 - 3 3: 259 505 - 3 3: 260 656 - 3 3: \n",
      "261 632 - 3 3: 262 432 - 1 1: 263 738 - 3 3: 264 1839 - Governance (4) 4: 265 977 - risk 3: 266 432 - 2 2: 267 900 - 3) risk 3: 268 626 - 4 4: 269 525 - and Manufactured Capital. \n",
      "\n",
      "Metrics: 1 1: 270 554 - 2 2: \n",
      "271 454 - 3 (risk) 3: 272 530 - 3 3: 273 405 - 4 4: 274 423 - 3 3: 275 1278 - 3 (risk) 3: 276 631 - 2 2: 277 1936 - governance 4: 278 583 - 4 4: 279 659 - 4 4: 280 547 - 3 3: \n",
      "281 624 - 1 1: 282 495 - 3 3: 283 705 - 3 3: 284 472 - 1 1: 285 572 - 3 3: 286 1927 - 3 3: 287 531 - 2 2: 288 1570 - governance 4: 289 465 - 4 4: 290 732 - 3 3: \n",
      "291 495 - 2 2: 292 503 - 2 2: 293 556 - 2 2: 294 690 - 4 4: 295 583 - 3 3: 296 745 - metrics 1: 297 553 - 3 3: 298 456 - 4 4: 299 644 - 3 3: 300 943 - Governance (4) 4: \n",
      "301 998 - Governance (4) 4: 302 911 - 3 (risk) 3: 303 552 - 2 2: 304 499 - 2 2: 305 697 - 4 4: 306 926 - 2 2: 307 605 - 3 3: 308 616 - 3 3: 309 515 - 4 4: 310 508 - 4 4: \n",
      "311 642 - 4 4: 312 675 - 2 2: 313 546 - 4 4: 314 526 - 2 2: 315 501 - 4 4: 316 541 - 3 3: 317 490 - 3 3: 318 409 - 4 4: 319 517 - Metrics: 1 1: 320 1056 - 3 (risk) 3: \n"
     ]
    }
   ],
   "source": [
    "texts = df[\"text\"].to_list()\n",
    "prompt = '''\n",
    "Classify the following sentence in one of the four classes: ('metrics':1, 'strategy': 2, 'risk': 3,'governance': 4).\n",
    "Answer only with the class number and noting else. The sentence is: \\n\n",
    "'''\n",
    "rez, rez_keys = batch_gpt_len(prompt, texts, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimit\\AppData\\Local\\Temp\\ipykernel_24720\\3670326254.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_rez ] = rez\n",
      "C:\\Users\\dimit\\AppData\\Local\\Temp\\ipykernel_24720\\3670326254.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_label] = rez_keys\n"
     ]
    }
   ],
   "source": [
    "col_rez = \"gpt_rez\"\n",
    "col_label = \"gpt_label\"\n",
    "df[col_rez ] = rez\n",
    "df[col_label] = rez_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"chat_gpt_tcdf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 1], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[col_label].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimit\\AppData\\Local\\Temp\\ipykernel_30608\\2609781461.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df[df[col_label] != 1][df[col_label] != 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prediction_VALUE</th>\n",
       "      <th>gpt_rez</th>\n",
       "      <th>gpt_label</th>\n",
       "      <th>gpt_rez-s</th>\n",
       "      <th>gpt_label-s</th>\n",
       "      <th>gpt_rez-c</th>\n",
       "      <th>gpt_label-c</th>\n",
       "      <th>gpt_rez-e</th>\n",
       "      <th>gpt_label-e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, label, prediction, prediction_VALUE, gpt_rez, gpt_label, gpt_rez-s, gpt_label-s, gpt_rez-c, gpt_label-c, gpt_rez-e, gpt_label-e]\n",
       "Index: []"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select rows that have gpt_label not 1 or 0\n",
    "df[df[col_label] != 1][df[col_label] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the gpt_label-e to 0 where gpt_rez-e is No.\n",
    "df.loc[df[col_rez] == \"No.\", col_label] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpt_label\n",
       "3    123\n",
       "4     98\n",
       "2     60\n",
       "1     39\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the the different values in the gpt_label column\n",
    "df[col_label].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the gpt_label wiht 1 whre the gpt_label is not -1\n",
    "df.loc[df[col_label] == 2, col_label] = 1\n",
    "df.loc[df[col_label] == -1, col_label] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4569825209633571, 0.5080553209179025, 0.38449680573647527, None)\n",
      "[[23  9  6 11]\n",
      " [15 49 83 50]\n",
      " [ 0  2 28 18]\n",
      " [ 1  0  6 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.47      0.52        49\n",
      "           2       0.82      0.25      0.38       197\n",
      "           3       0.23      0.58      0.33        48\n",
      "           4       0.19      0.73      0.31        26\n",
      "\n",
      "    accuracy                           0.37       320\n",
      "   macro avg       0.46      0.51      0.38       320\n",
      "weighted avg       0.64      0.37      0.39       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the precision and f1 score for df columns label and prediction\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "sent_col = col_label\n",
    "print(precision_recall_fscore_support(df['label'], df[sent_col], average='macro'))\n",
    "\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(df['label'], df[sent_col]))\n",
    "\n",
    "# performnce report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(df['label'], df[sent_col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column with the gpt_label-all that is 1 if any of the gpt_label-e, gpt_label-s, gpt_label-c is 1\n",
    "df[\"gpt_label-all\"] = df[\"gpt_label-e\"] + df[\"gpt_label-s\"] + df[\"gpt_label-c\"]\n",
    "df.loc[df[\"gpt_label-all\"] > 0, \"gpt_label-all\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7357046826282216, 0.821875, 0.7571223860296797, None)\n",
      "[[ 67  13]\n",
      " [ 62 258]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.84      0.64        80\n",
      "           1       0.95      0.81      0.87       320\n",
      "\n",
      "    accuracy                           0.81       400\n",
      "   macro avg       0.74      0.82      0.76       400\n",
      "weighted avg       0.87      0.81      0.83       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_col = \"gpt_label-s\"\n",
    "print(precision_recall_fscore_support(df['label'], df[sent_col], average='macro'))\n",
    "\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(df['label'], df[sent_col]))\n",
    "\n",
    "# performnce report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(df['label'], df[sent_col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
